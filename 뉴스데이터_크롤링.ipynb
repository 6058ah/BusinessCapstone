{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "뉴스데이터 크롤링.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAibO4CDyVjk8XVBFWiQWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6058ah/BusinessCapstone/blob/master/%EB%89%B4%EC%8A%A4%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%81%AC%EB%A1%A4%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87RqPsLxkriB"
      },
      "source": [
        " # -*- coding: utf-8 -*-\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "< naver 뉴스 검색시 리스트 크롤링하는 프로그램 > _select사용\n",
        "- 크롤링 해오는 것 : 링크,제목,신문사,내용요약본\n",
        "- 내용요약본  -> 정제 작업 필요\n",
        "- 리스트 -> 딕셔너리 -> df -> 엑셀로 저장\n",
        "'''''''''''''''''''''\n",
        "\n",
        "#각 크롤링 결과 저장하기 위한 리스트 선언\n",
        "title_text=[]\n",
        "link_text=[]\n",
        "source_text=[]\n",
        "contents_text=[]\n",
        "result={}\n",
        "\n",
        "#엑셀로 저장하기 위한 변수\n",
        "RESULT_PATH ='C:/'  #결과 저장할 경로\n",
        "now = datetime.now() #파일이름 현 시간으로 저장하기\n",
        "\n",
        "#내용 정제화 함수\n",
        "def contents_cleansing(contents):\n",
        "    first_cleansing_contents = re.sub('<dl>.*?</a> </div> </dd> <dd>', '',str(contents)).strip()  #앞에 필요없는 부분 제거\n",
        "    second_cleansing_contents = re.sub('<ul class=\"relation_lst\">.*?</dd>', '', first_cleansing_contents).strip()#뒤에 필요없는 부분 제거 (새끼 기사)\n",
        "    third_cleansing_contents = re.sub('<.+?>', '', second_cleansing_contents).strip()\n",
        "    contents_text.append(third_cleansing_contents)\n",
        "    #print(contents_text)\n",
        "\n",
        "#크롤링 시작\n",
        "def crawler(maxpage,query,sort,s_date,e_date):\n",
        "    s_from = s_date.replace(\".\",\"\")\n",
        "    e_to = e_date.replace(\".\",\"\")\n",
        "    page = 1\n",
        "    maxpage_t =(int(maxpage)-1)*10+1   # 11= 2페이지 21=3페이지 31=4페이지  ...81=9페이지 , 91=10페이지, 101=11페이지\n",
        "    while page <= maxpage_t:\n",
        "        url = \"https://search.naver.com/search.naver?where=news&query=\" + query + \"&sort=\"+sort+\"&ds=\" + s_date + \"&de=\" + e_date + \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(page)\n",
        "        response = requests.get(url)\n",
        "        html = response.text\n",
        "\n",
        "        #뷰티풀소프의 인자값 지정\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "        #<a>태그에서 제목과 링크주소 (a 태그 중 class 명이 news_tit인 것)\n",
        "        atags = soup.find_all('a', 'news_tit')\n",
        "        for atag in atags:\n",
        "            title = atag.get('title')\n",
        "            title_text.append(title)     #제목\n",
        "            link_text.append(atag['href'])   #링크주소\n",
        "\n",
        "        #신문사 추출 (a 태그 중 class 명이 info press인 것)\n",
        "        source_lists = soup.find_all('a', 'info press')\n",
        "        for source_list in source_lists:\n",
        "            source_text.append(source_list.text)    #신문사\n",
        "\n",
        "        #본문요약본 (a 태그 중 class 명이 api_txt_lines dsc_txt_wrap인 것)\n",
        "        contents_lists = soup.find_all('a','api_txt_lines dsc_txt_wrap')\n",
        "        for contents_list in contents_lists:\n",
        "            contents_cleansing(contents_list) #본문요약 정제화\n",
        "\n",
        "        #모든 리스트 딕셔너리형태로 저장\n",
        "        result= {\"title\":title_text ,  \"source\" : source_text ,\"contents\": contents_text ,\"link\":link_text }\n",
        "        df = pd.DataFrame(result)  #df로 변환\n",
        "        page += 10\n",
        "\n",
        "    # 새로 만들 파일이름 지정\n",
        "    outputFileName = '%s-%s-%s  %s시 %s분 %s초 merging.xlsx' % (now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
        "    df.to_excel(RESULT_PATH+outputFileName,sheet_name='sheet1')\n",
        "\n",
        "#메인함수\n",
        "def main():\n",
        "    info_main = input(\"=\"*50+\"\\n\"+\"입력 형식에 맞게 입력해주세요.\"+\"\\n\"+\" 시작하시려면 Enter를 눌러주세요.\"+\"\\n\"+\"=\"*50)\n",
        "    maxpage = input(\"최대 크롤링할 페이지 수 입력하시오: \") #10,20...\n",
        "    query = input(\"검색어 입력: \") #네이버, 부동산...\n",
        "    sort = input(\"뉴스 검색 방식 입력(관련도순=0  최신순=1  오래된순=2): \")    #관련도순=0  최신순=1  오래된순=2\n",
        "    s_date = input(\"시작날짜 입력(2019.01.04):\")  #2019.01.04\n",
        "    e_date = input(\"끝날짜 입력(2019.01.05):\")   #2019.01.05\n",
        "    crawler(maxpage,query,sort,s_date,e_date)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "xMEEyXIvkxkq",
        "outputId": "5b769fea-a5eb-4ceb-9afa-290d05d2fd53"
      },
      "source": [
        "main()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "입력 형식에 맞게 입력해주세요.\n",
            " 시작하시려면 Enter를 눌러주세요.\n",
            "==================================================\n",
            "최대 크롤링할 페이지 수 입력하시오: 10\n",
            "검색어 입력: 2차전지\n",
            "뉴스 검색 방식 입력(관련도순=0  최신순=1  오래된순=2): 0\n",
            "시작날짜 입력(2019.01.04):2019.01.01\n",
            "끝날짜 입력(2019.01.05):2021.05.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-b23991ec3647>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m    \u001b[0ms_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"시작날짜 입력(2019.01.04):\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#2019.01.04\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m    \u001b[0me_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"끝날짜 입력(2019.01.05):\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#2019.01.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m    \u001b[0mcrawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxpage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-b23991ec3647>\u001b[0m in \u001b[0;36mcrawler\u001b[0;34m(maxpage, query, sort, s_date, e_date)\u001b[0m\n\u001b[1;32m     71\u001b[0m    \u001b[0;31m# 새로 만들 파일이름 지정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m    \u001b[0moutputFileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s-%s-%s  %s시 %s분 %s초 merging.xlsx'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m    \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULT_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moutputFileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sheet1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m#메인함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[1;32m   2030\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2031\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2032\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2033\u001b[0m         )\n\u001b[1;32m   2034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mSave\u001b[0m \u001b[0mworkbook\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openpyxl/workbook/workbook.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0msave_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0msave_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openpyxl/writer/excel.py\u001b[0m in \u001b[0;36msave_workbook\u001b[0;34m(workbook, filename)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowZip64\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/2021-5-3  14시 12분 59초 merging.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncn4O9Fgk21p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}